{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a90f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file with standard pickle...\n",
      "Loaded 1430888 rows.\n",
      "Upload complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# 1. Use standard pickle to open the file first\n",
    "print(\"Opening file with standard pickle...\")\n",
    "with open('SBS_DT.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# 2. Convert to DataFrame if it's not already\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Loaded {len(df)} rows.\")\n",
    "\n",
    "# 3. Upload to Postgres\n",
    "engine = create_engine('postgresql://postgres:overall@localhost:5432/main_db')\n",
    "df.to_sql('sales_main_web', engine, if_exists='replace', index=False, chunksize=5000)\n",
    "print(\"Upload complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4536fdf1",
   "metadata": {},
   "source": [
    "##### update scipt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb55b874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening SBS_DT_UPDATE.pkl...\n",
      "Loaded 31760 rows from UPDATE file.\n",
      "UPDATE rows in Jan 2026: 31760\n",
      "Reading existing Jan 2026 data from database...\n",
      "Existing Jan 2026 rows in DB: 31140\n",
      "Combining + deduplicating Jan 2026 by IdReal2...\n",
      "Jan combined: 62900 -> 31765 (removed 31135 duplicates)\n",
      "Deleting existing Jan 2026 rows from DB...\n",
      "Appending deduplicated Jan 2026 rows...\n",
      "Done: Updated January 2026 only, deduped by IdReal2.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# DB engine\n",
    "engine = create_engine('postgresql://postgres:overall@localhost:5432/main_db')\n",
    "\n",
    "# --- Config (adjust if your date column name is different) ---\n",
    "TABLE = \"sales_main_web\"\n",
    "DATE_COL = \"CD\"          # your date column (you used \"CD\" in earlier SQL)\n",
    "DEDUP_COL = \"IdReal2\"\n",
    "\n",
    "JAN_START = \"2026-01-01\"\n",
    "FEB_START = \"2026-03-01\"\n",
    "\n",
    "# 1) Load UPDATE file\n",
    "print(\"Opening SBS_DT_UPDATE.pkl...\")\n",
    "with open(\"SBS_DT_UPDATE.pkl\", \"rb\") as f:\n",
    "\n",
    "\n",
    "    data_update = pickle.load(f)\n",
    "\n",
    "df_update = pd.DataFrame(data_update)\n",
    "print(f\"Loaded {len(df_update)} rows from UPDATE file.\")\n",
    "\n",
    "# Ensure date column is datetime (important for filtering)\n",
    "df_update[DATE_COL] = pd.to_datetime(df_update[DATE_COL], errors=\"coerce\")\n",
    "\n",
    "# Keep only January 2026 rows from the UPDATE file\n",
    "df_update_jan = df_update[\n",
    "    (df_update[DATE_COL] >= JAN_START) & (df_update[DATE_COL] < FEB_START)\n",
    "].copy()\n",
    "print(f\"UPDATE rows in Jan 2026: {len(df_update_jan)}\")\n",
    "\n",
    "# 2) Read only January 2026 from DB (not whole table)\n",
    "print(\"Reading existing Jan 2026 data from database...\")\n",
    "query_existing_jan = text(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {TABLE}\n",
    "    WHERE \"{DATE_COL}\" >= :jan_start\n",
    "      AND \"{DATE_COL}\" <  :feb_start\n",
    "\"\"\")\n",
    "\n",
    "df_existing_jan = pd.read_sql(query_existing_jan, engine, params={\n",
    "    \"jan_start\": JAN_START,\n",
    "    \"feb_start\": FEB_START\n",
    "})\n",
    "print(f\"Existing Jan 2026 rows in DB: {len(df_existing_jan)}\")\n",
    "\n",
    "# 3) Combine ONLY Jan 2026 data, and deduplicate by IdReal2\n",
    "# Put existing first, update second -> keep='last' means UPDATE wins on conflicts\n",
    "print(\"Combining + deduplicating Jan 2026 by IdReal2...\")\n",
    "df_combined_jan = pd.concat([df_existing_jan, df_update_jan], ignore_index=True)\n",
    "\n",
    "before = len(df_combined_jan)\n",
    "df_dedup_jan = df_combined_jan.drop_duplicates(subset=[DEDUP_COL], keep=\"last\")\n",
    "after = len(df_dedup_jan)\n",
    "\n",
    "print(f\"Jan combined: {before} -> {after} (removed {before - after} duplicates)\")\n",
    "\n",
    "# 4) Replace ONLY January 2026 in Postgres (safe pattern: DELETE that month, then APPEND back)\n",
    "print(\"Deleting existing Jan 2026 rows from DB...\")\n",
    "delete_jan = text(f\"\"\"\n",
    "    DELETE FROM {TABLE}\n",
    "    WHERE \"{DATE_COL}\" >= :jan_start\n",
    "      AND \"{DATE_COL}\" <  :feb_start\n",
    "\"\"\")\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(delete_jan, {\"jan_start\": JAN_START, \"feb_start\": FEB_START})\n",
    "\n",
    "print(\"Appending deduplicated Jan 2026 rows...\")\n",
    "df_dedup_jan.to_sql(TABLE, engine, if_exists=\"append\", index=False, chunksize=5000)\n",
    "\n",
    "print(\"Done: Updated January 2026 only, deduped by IdReal2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87a863a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 116 rows to cross_selling_rustavi_jan_2026_with_tanam.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql://postgres:overall@localhost:5432/main_db')\n",
    "\n",
    "query = \"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    \"IdTanam\",\n",
    "    \"Tanam\",\n",
    "    \"Zedd\",\n",
    "    \"IdProdG\",\n",
    "    \"ProdG\",\n",
    "    \"Tanxa\",\n",
    "    \"CD\",\n",
    "    \"UN\"\n",
    "  FROM sales_main_web\n",
    "  WHERE \"CD\" >= DATE '2026-01-01'\n",
    "    AND \"CD\" <  DATE '2026-02-01'\n",
    "    AND \"UN\" = 'რუსთავი' and \"IdTanam\" = 241\n",
    "    AND \"IdProdG\" NOT IN (4,5,6,7,14,17,18,19,20,21)\n",
    "),\n",
    "basket AS (\n",
    "  SELECT\n",
    "    \"IdTanam\",\n",
    "    \"Tanam\",\n",
    "    \"Zedd\",\n",
    "    \"ProdG\",\n",
    "    COUNT(*) AS lines_excl5,\n",
    "    (COUNT(*) >= 3)::int AS flag_ge3\n",
    "  FROM base\n",
    "  WHERE \"IdProdG\" <> 5\n",
    "  GROUP BY \"IdTanam\", \"Tanam\", \"Zedd\", \"ProdG\"\n",
    ")\n",
    "SELECT\n",
    "  \"IdTanam\",\n",
    "  \"Tanam\",\n",
    "  \"ProdG\"\n",
    "  \"Zedd\",\n",
    "  lines_excl5,\n",
    "  flag_ge3,\n",
    "  ROUND( (AVG(flag_ge3) OVER (PARTITION BY \"IdTanam\"))::numeric, 4 ) AS cross_selling_for_tanam\n",
    "FROM basket\n",
    "ORDER BY \"IdTanam\", lines_excl5 DESC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "output_file = \"cross_selling_rustavi_jan_2026_with_tanam.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Exported {len(df)} rows to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
